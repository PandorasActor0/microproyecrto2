# -*- coding: utf-8 -*-
"""numeros.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14g8bShBLdcidv0QG9v5ESJLm4BnBza7Z

ESTE CODIGO SE BASO EN EL DE Ringa Tech para el uso de tensorflow en html

Importamos las librerias
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import math

"""Importamos el dataset MNIST"""

datos, metadatos = tfds.load('mnist', as_supervised=True, with_info=True)

"""dividimos el dataset en entrenamiento y testeo"""

datos_entrenamiento, datos_pruebas = datos['train'], datos['test']

"""Optenemos las etiquetas"""

nombres_clases = metadatos.features['label'].names

"""Normalizamos los datos"""

def normalizar(imagenes, etiquetas):
  imagenes = tf.cast(imagenes, tf.float32)
  imagenes /= 255 #Aqui lo pasa de 0-255 a 0-1
  return imagenes, etiquetas

datos_entrenamiento = datos_entrenamiento.map(normalizar)
datos_pruebas = datos_pruebas.map(normalizar)

"""Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)"""

datos_entrenamiento = datos_entrenamiento.cache()
datos_pruebas = datos_pruebas.cache()

"""Creamos el modelo"""

modelo = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax) #Para redes de clasificacion
])

"""Compilamos el modelo"""

modelo.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

"""Los numeros de datos en entrenamiento y pruebas (60k y 10k)"""

num_ej_entrenamiento = metadatos.splits["train"].num_examples
num_ej_pruebas = metadatos.splits["test"].num_examples

"""El trabajo por lotes permite que entrenamientos con gran cantidad de datos se haga de manera mas eficiente"""

TAMANO_LOTE = 32

"""Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria para que la red
no se vaya a aprender el orden de las cosas
"""

datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE)
datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)

"""Entrenar"""

historial = modelo.fit(datos_entrenamiento, epochs=20, steps_per_epoch= math.ceil(num_ej_entrenamiento/TAMANO_LOTE))

"""Guardamos el modelo"""

modelo.save('numeros.h5')

!pip install tensorflowjs

!mkdir carpeta_salida

!tensorflowjs_converter --input_format keras numeros.h5 carpeta_salida

!ls carpeta_salida